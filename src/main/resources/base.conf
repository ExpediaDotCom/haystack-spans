akka {
  loggers = ["akka.event.slf4j.Slf4jLogger"]

  loglevel = "INFO"

  actor {
    default-dispatcher {
      fork-join-executor {
        parallelism-min = 4
        parallelism-factor = 2.0
        parallelism-max = 8
      }
      throughput = 50
    }
  }

  kafka.consumer {
    # Tuning property of scheduled polls.
    poll-interval = 100ms

    # Tuning property of the `KafkaConsumer.poll` parameter.
    # Note that non-zero value means that blocking of the thread that
    # is executing the stage will be blocked.
    poll-timeout = 100ms

    # The stage will be await outstanding offset commit requests before
    # shutting down, but if that takes longer than this timeout it will
    # stop forcefully.
    stop-timeout = 30s

    # How long to wait for `KafkaConsumer.close`
    close-timeout = 15s

    # If offset commit requests are not completed within this timeout
    # the returned Future is completed `TimeoutException`.
    commit-timeout = 15s

    # If the KafkaConsumer can't connect to the broker the poll will be
    # aborted after this timeout. The KafkaConsumerActor will throw
    # org.apache.kafka.common.errors.WakeupException which will be ignored
    # until max-wakeups limit gets exceeded.
    wakeup-timeout = 3s

    # After exceeding maxinum wakeups the consumer will stop and the stage will fail.
    max-wakeups = 10

    # Fully qualified config path which holds the dispatcher configuration
    # to be used by the KafkaConsumerActor. Some blocking may occur.
    use-dispatcher = "akka.kafka.default-dispatcher"

    # Properties defined by org.apache.kafka.clients.consumer.ConsumerConfig
    # can be defined in this configuration section.
    kafka-clients {
      # Disable auto-commit by default
      enable.auto.commit = false
    }
  }
}

collector {
  topic = "stitch-spans"
  write.batch {
    size = 250
    timeout.ms = 250
  }
  parallelism = 2
  commit.batch.size = 1000 # recommeded to keep it as a multiple of write.batch.size
}

cassandra {
  # multiple endpoints can be provided as comma separated
  endpoints: "cassandra"

  # if auto.discovery.enabled is true, we ignore the manually supplied endpoints(above).
  auto.discovery {
    enabled: false
#   aws: {
#      region: "us-west-2"
#      tags: {
#        name: "cassandra"
#      }
#    }
  }

  connections {
    max.per.host = 10
    read.timeout.ms = 5000
    conn.timeout.ms = 10000
    keep.alive = true
  }

  consistency.level = "one"
  ttl.sec = 86400

  keyspace: {
    name: "haystack"
    auto.create: true
    table.name: "spans"
  }
}

elasticsearch {
  host = "elasticSearch"
  port = 9200
  conn.timeout.ms = 10000
  read.timeout.ms = 5000
  consistency.level = "one"
  index {
    name.prefix = "haystack-span"
    type = "spans"
  }
}

reload {
  config {
    endpoint = "elasticSearch"
    database = "reloadConfigs"
  }
  interval.ms = 600000 # -1 will imply 'no reload'
}