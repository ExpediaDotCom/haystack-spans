span.accumulate {
  store {
    all.max.entries = 20000
  }
  window.ms = 1000
  poll.ms = 1000
  logging.enabled = false
}

# test 
kafka {
  close.stream.timeout.ms = 300

  changelog {
    enabled = true
    logConfig {
      retention.bytes = 104857600 // 100 MB
      retention.ms = 86400 // 1 day log retention
    }
  }

  streams {
    application.id = "haystack-trace-indexer"
    bootstrap.servers = "kafka-svc:9092"
    num.stream.threads = 4
    auto.offset.reset = latest
  }

  producer {
    topic = "span-buffer"
  }

  consumer {
    topic = "spans"
  }
}


cassandra {
  # multiple endpoints can be provided as comma separated
  endpoints: "cassandra"

  # defines the max inflight writes for cassandra
  max.inflight.requests = 100

  # if auto.discovery.enabled is true, we ignore the manually supplied endpoints(above).
  auto.discovery {
    enabled: false
    #   aws: {
    #      region: "us-west-2"
    #      tags: {
    #        name: "cassandra"
    #      }
    #    }
  }

  connections {
    max.per.host = 10
    read.timeout.ms = 5000
    conn.timeout.ms = 10000
    keep.alive = true
  }

  consistency.level = "one"
  ttl.sec = 86400

  keyspace: {
    auto.create.schema = "cassandra_cql_schema"
    name: "haystack"
    table.name: "traces"
  }
}

elasticsearch {
  endpoint = "http://elasticsearch:9200"
  max.inflight.requests = 50
  conn.timeout.ms = 10000
  read.timeout.ms = 5000
  consistency.level = "one"
  index {
    template {
      json = "some_template_json"
    }

    name.prefix = "haystack-traces"
    type = "spans"
  }
}

reload {
  tables {
    index.fields.config = "indexing-fields"
  }
  config {
    endpoint = "http://elasticsearch:9200"
    database.name = "reload-configs"
  }
  interval.ms = 600
  startup.load = false
}