health.status.path = "/app/isHealthy"

span.accumulate {
  store {
    min.traces.per.cache = 1000 # this defines the minimum traces in each cache before eviction check is applied. This is also useful for testing the code
    all.max.entries = 20000 # this is the maximum number of spans that can live across all the stores
  }
  window.ms = 10000
  poll.ms = 2000
  packer = snappy
}

kafka {
  close.stream.timeout.ms = 30000

  topic.consume = "spans"
  topic.produce = "span-buffer"
  num.stream.threads = 2

  max.wakeups = 5
  wakeup.timeout.ms = 5000

  commit.offset {
    retries = 3
    backoff.ms = 200
  }

  # consumer specific configurations
  consumer {
    group.id = "haystack-trace-indexer"
    bootstrap.servers = "kafkasvc:9092"
    auto.offset.reset = "latest"
    enable.auto.commit = "false"
  }

  # producer specific configurations
  producer {
    bootstrap.servers = "kafkasvc:9092"
  }
}


cassandra {
  # multiple endpoints can be provided as comma separated
  endpoints: "cassandra"

  # defines the max inflight writes for cassandra
  max.inflight.requests = 100

  # if auto.discovery.enabled is true, we ignore the manually supplied endpoints(above).
  auto.discovery {
    enabled: false
    #   aws: {
    #      region: "us-west-2"
    #      tags: {
    #        name: "cassandra"
    #      }
    #    }
  }

  connections {
    max.per.host = 10
    read.timeout.ms = 5000
    conn.timeout.ms = 10000
    keep.alive = true
  }

  consistency.level = "one"
  on.error.consistency.level = [
    "com.datastax.driver.core.exceptions.UnavailableException",
    "any"
  ]

  ttl.sec = 86400

  keyspace {
    # auto creates the keyspace and table name in cassandra(if absent)
    # if schema field is empty or not present, then no operation is performed
    auto.create.schema = "cassandra_cql_schema_1"
    name = "haystack"
    table.name = "traces"
  }

  retries {
    max = 10
    backoff {
      initial.ms = 250
      factor = 2
    }
  }
}

service.metadata {
  enabled = true
  flush {
    interval.sec = 60
    operation.count = 10000
  }
  es {
    endpoint = "http://elasticsearch:9200"
    conn.timeout.ms = 10000
    read.timeout.ms = 5000
    consistency.level = "one"
    index {
      # apply the template before starting the client, if json is empty, no operation is performed
      template.json = "some_template_json"
      name = "service-metadata"
      type = "metadata"
    }
    # defines settings for bulk operation like max inflight bulks, number of documents and the total size in a single bulk
    bulk.max {
      docs {
        count = 100
        size.kb = 1000
      }
      inflight = 10
    }
    retries {
      max = 10
      backoff {
        initial.ms = 100
        factor = 2
      }
    }
  }
}

elasticsearch {
  endpoint = "http://elasticsearch:9200"
  max.inflight.requests = 50
  conn.timeout.ms = 10000
  read.timeout.ms = 5000
  max.connections.per.route = 10
  consistency.level = "one"
  index {
    template {
      json = "some_template_json"
    }

    name.prefix = "haystack-traces"
    hour.bucket = 6
    type = "spans"
  }
  # defines settings for bulk operation like max inflight bulks, number of documents and the total size in a single bulk
  bulk.max {
    docs {
      count = 100
      size.kb = 1000
    }
    inflight = 10
  }

  retries {
    max = 10
    backoff {
      initial.ms = 1000
      factor = 2
    }
  }
}

reload {
  tables {
    index.fields.config = "whitelist-index-fields"
  }
  config {
    endpoint = "http://elasticsearch:9200"
    database.name = "reload-configs"
  }
  interval.ms = 600
  startup.load = false
}